{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d49079",
   "metadata": {},
   "source": [
    "# Concept-Based Model with Interventions\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and prepare data with concept annotations\n",
    "2. Build a concept-based neural network with an encoder and predictor\n",
    "3. Train the model on both concept and task predictions\n",
    "4. Apply various intervention strategies to manipulate concept predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ced03c",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We import the necessary libraries:\n",
    "- **PyTorch**: for neural network building blocks\n",
    "- **sklearn**: for evaluation metrics\n",
    "- **torch_concepts**: for concept annotations, layers, and intervention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0f0e684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.551141Z",
     "start_time": "2025-11-17T09:09:45.740442Z"
    }
   },
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torch_concepts import Annotations, AxisAnnotation\n",
    "from torch_concepts.data import ToyDataset\n",
    "from torch_concepts.nn import (\n",
    "    LinearZC,\n",
    "    LinearCC,\n",
    "    GroundTruthIntervention,\n",
    "    UncertaintyInterventionPolicy, \n",
    "    intervention, \n",
    "    DoIntervention, \n",
    "    DistributionIntervention, \n",
    "    UniformPolicy, \n",
    "    RandomPolicy\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b3341630",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "We load the XOR toy dataset and prepare the training data:\n",
    "- **Features (x_train)**: input features for the model\n",
    "- **Concepts (c_train)**: intermediate concept labels (duplicated to create 6 concepts)\n",
    "- **Targets (y_train)**: task labels to predict\n",
    "- **Names**: concept and task attribute names for annotations"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7b49772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.559580Z",
     "start_time": "2025-11-17T09:09:50.555009Z"
    }
   },
   "source": [
    "# Hyperparameters\n",
    "latent_dims = 10\n",
    "n_epochs = 500\n",
    "n_samples = 1000\n",
    "concept_reg = 0.5\n",
    "\n",
    "# Load toy XOR dataset\n",
    "data = ToyDataset('xor', size=n_samples, random_state=42)\n",
    "x_train = data.data\n",
    "c_train = data.concept_labels\n",
    "y_train = data.target_labels\n",
    "concept_names = data.concept_attr_names\n",
    "task_names = data.task_attr_names\n",
    "\n",
    "# Duplicate concept labels to create 6 concepts (C1, C2, C3, C4, C5, C6)\n",
    "c_train = torch.concat([c_train, c_train, c_train], dim=1)\n",
    "\n",
    "# Get dimensions\n",
    "n_features = x_train.shape[1]\n",
    "n_concepts = c_train.shape[1]\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Features shape: {x_train.shape}\")\n",
    "print(f\"  Concepts shape: {c_train.shape}\")\n",
    "print(f\"  Targets shape: {y_train.shape}\")\n",
    "print(f\"  Number of features: {n_features}\")\n",
    "print(f\"  Number of concepts: {n_concepts}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded:\n",
      "  Features shape: torch.Size([1000, 2])\n",
      "  Concepts shape: torch.Size([1000, 6])\n",
      "  Targets shape: torch.Size([1000, 1])\n",
      "  Number of features: 2\n",
      "  Number of concepts: 6\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "06618192",
   "metadata": {},
   "source": [
    "## 3. Annotations Object\n",
    "\n",
    "The `Annotations` object is a key component that provides semantic meaning to tensor dimensions:\n",
    "- It maps axis indices to `AxisAnnotation` objects\n",
    "- Each `AxisAnnotation` contains names (labels) for features along that axis\n",
    "- This enables human-readable concept manipulation and intervention\n",
    "\n",
    "Here we create:\n",
    "- **c_annotations**: annotations for the 6 concepts (C1-C6)\n",
    "- **y_annotations**: annotations for the task output"
   ]
  },
  {
   "cell_type": "code",
   "id": "0e7a2a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.632389Z",
     "start_time": "2025-11-17T09:09:50.630451Z"
    }
   },
   "source": [
    "# Create annotations for concepts and targets\n",
    "c_annotations = Annotations({1: AxisAnnotation(concept_names + ['C3', 'C4', 'C5', 'C6'])})\n",
    "y_annotations = Annotations({1: AxisAnnotation(task_names)})\n",
    "\n",
    "print(f\"Concept annotations:\")\n",
    "print(f\"  Shape: {c_annotations.shape}\")\n",
    "print(f\"  Axis 1 names: {c_annotations[1].labels}\")\n",
    "print(f\"\\nTask annotations:\")\n",
    "print(f\"  Shape: {y_annotations.shape}\")\n",
    "print(f\"  Axis 1 names: {y_annotations[1].labels}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept annotations:\n",
      "  Shape: (-1, 6)\n",
      "  Axis 1 names: ['C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
      "\n",
      "Task annotations:\n",
      "  Shape: (-1, 1)\n",
      "  Axis 1 names: ['xor']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "69e32f29",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "We build a concept bottleneck model with three components:\n",
    "\n",
    "1. **Encoder**: A simple neural network that maps input features to a latent embedding\n",
    "2. **Encoder Layer** (`LinearZC`): Maps the embedding to concept endogenous\n",
    "3. **Task Predictor** (`LinearCC`): Maps concept endogenous to task predictions\n",
    "\n",
    "The model is wrapped in a `ModuleDict` to enable easier intervention on specific layers."
   ]
  },
  {
   "cell_type": "code",
   "id": "02fab0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.642470Z",
     "start_time": "2025-11-17T09:09:50.639480Z"
    }
   },
   "source": [
    "# Build the encoder (features -> embedding)\n",
    "encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_features, latent_dims),\n",
    "    torch.nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "# Build the concept encoder (embedding -> concepts)\n",
    "encoder_layer = LinearZC(\n",
    "    in_features=latent_dims,\n",
    "    out_features=c_annotations.shape[1]\n",
    ")\n",
    "\n",
    "# Build the task predictor (concepts -> task)\n",
    "y_predictor = LinearCC(\n",
    "    in_features_endogenous=c_annotations.shape[1],\n",
    "    out_features=y_annotations.shape[1]\n",
    ")\n",
    "\n",
    "# Wrap all components in a ModuleDict for easier intervention\n",
    "model = torch.nn.ModuleDict({\n",
    "    \"encoder\": encoder,\n",
    "    \"encoder_layer\": encoder_layer,\n",
    "    \"y_predictor\": y_predictor,\n",
    "})\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nEncoder layer representation:\")\n",
    "print(f\"  Input: embedding of size {latent_dims}\")\n",
    "print(f\"  Output: concept endogenous of size {c_annotations.shape[1]}\")\n",
    "print(f\"\\nTask predictor representation:\")\n",
    "print(f\"  Input: concept endogenous of size {c_annotations.shape[1]}\")\n",
    "print(f\"  Output: task endogenous of size {y_annotations.shape[1]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "ModuleDict(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (encoder_layer): ProbEncoderFromEmb(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "      (1): Unflatten(dim=-1, unflattened_size=(6,))\n",
      "    )\n",
      "  )\n",
      "  (y_predictor): ProbPredictor(\n",
      "    (predictor): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=1, bias=True)\n",
      "      (1): Unflatten(dim=-1, unflattened_size=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Encoder layer representation:\n",
      "  Input: embedding of size 10\n",
      "  Output: concept logits of size 6\n",
      "\n",
      "Task predictor representation:\n",
      "  Input: concept logits of size 6\n",
      "  Output: task logits of size 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "9eed2931",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "We train the model with a combined loss:\n",
    "- **Concept loss**: BCE loss between predicted and true concept labels\n",
    "- **Task loss**: BCE loss between predicted and true task labels\n",
    "- **Total loss**: `concept_loss + concept_reg * task_loss`\n",
    "\n",
    "This encourages the model to learn meaningful concept representations while also solving the task."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Setup training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    emb = encoder(x_train)\n",
    "    c_pred = encoder_layer(embedding=emb)\n",
    "    y_pred = y_predictor(endogenous=c_pred)\n",
    "\n",
    "    # Compute loss\n",
    "    concept_loss = loss_fn(c_pred, c_train)\n",
    "    task_loss = loss_fn(y_pred, y_train)\n",
    "    loss = concept_loss + concept_reg * task_loss\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log progress\n",
    "    if epoch % 100 == 0:\n",
    "        task_accuracy = accuracy_score(y_train, y_pred > 0.)\n",
    "        concept_accuracy = accuracy_score(c_train, c_pred > 0.)\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item():.2f} | Task Acc: {task_accuracy:.2f} | Concept Acc: {concept_accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ],
   "id": "8c7852dd613cf8b4"
  },
  {
   "cell_type": "markdown",
   "id": "59499d42",
   "metadata": {},
   "source": [
    "## 6. Baseline Predictions (No Intervention)\n",
    "\n",
    "Let's first see what the model predicts without any interventions."
   ]
  },
  {
   "cell_type": "code",
   "id": "892a2bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.834392Z",
     "start_time": "2025-11-17T09:09:50.831836Z"
    }
   },
   "source": [
    "# Get baseline predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "\n",
    "print(\"Baseline concept predictions (first 5 samples):\")\n",
    "print(c_pred[:5])\n",
    "print(\"\\nBaseline task predictions (first 5 samples):\")\n",
    "print(y_pred[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline concept predictions (first 5 samples):\n",
      "tensor([[ -4.8956,  20.1472,  -4.9395,  19.3860,  -1.9786,  21.0479],\n",
      "        [  9.6034,   5.6144,   8.3762,   4.9804,   7.0057,   4.9587],\n",
      "        [-13.6898, -16.0129, -15.2738, -16.3038, -12.4378, -17.0760],\n",
      "        [-18.1545,  14.0004, -18.9113,  11.6973,  -9.7617,  14.2617],\n",
      "        [  4.9382,  10.3747,   4.5033,  10.8236,   2.3549,  10.8078]])\n",
      "\n",
      "Baseline task predictions (first 5 samples):\n",
      "tensor([[ 0.6272],\n",
      "        [ 0.0130],\n",
      "        [-0.0849],\n",
      "        [ 0.1556],\n",
      "        [-0.3078]])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "abaa4cf3",
   "metadata": {},
   "source": [
    "## 7. Interventions\n",
    "\n",
    "Now we demonstrate different intervention strategies:\n",
    "\n",
    "### What are Interventions?\n",
    "Interventions allow us to manipulate the model's internal representations (concepts) during inference. This is useful for:\n",
    "- Understanding model behavior\n",
    "- Correcting mistakes\n",
    "- Testing counterfactual scenarios\n",
    "\n",
    "### Intervention Components:\n",
    "1. **Policy**: Decides *which* concepts to intervene on (e.g., UniformPolicy, RandomPolicy, UncertaintyInterventionPolicy)\n",
    "2. **Strategy**: Decides *how* to intervene (e.g., DoIntervention, GroundTruthIntervention, DistributionIntervention)\n",
    "3. **Layer**: Specifies *where* in the model to apply the intervention\n",
    "4. **Quantile**: Controls *how many* samples to intervene on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dfb55",
   "metadata": {},
   "source": [
    "### 7.1. Uncertainty + Ground Truth Intervention\n",
    "\n",
    "- **Policy**: UniformPolicy on concepts [C1, C4, C5, C6] + UncertaintyInterventionPolicy on task [xor]\n",
    "- **Strategy**: GroundTruthIntervention (use true concept values) + DoIntervention (set to constant 100)\n",
    "- This combination intervenes on uncertain predictions using ground truth for concepts and a constant for the task"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "int_policy_c = UniformPolicy(out_features=c_train.shape[1])\n",
    "int_strategy_c = GroundTruthIntervention(model=encoder_layer, ground_truth=torch.logit(c_train, eps=1e-6))\n",
    "\n",
    "print(\"Uncertainty + Ground Truth Intervention:\")\n",
    "with intervention(policies=int_policy_c,\n",
    "                  strategies=int_strategy_c,\n",
    "                  target_concepts=[0, 1]) as new_encoder_layer:\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = new_encoder_layer(embedding=emb)\n",
    "    y_pred = model[\"y_predictor\"](endogenous=c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])\n",
    "    print(\"\\nGround truth (first 5):\")\n",
    "    print(torch.logit(c_train, eps=1e-6)[:5])"
   ],
   "id": "bdf868fe035152e0"
  },
  {
   "cell_type": "markdown",
   "id": "189cec30",
   "metadata": {},
   "source": [
    "### 7.2. Do Intervention + Uniform Policy\n",
    "\n",
    "- **Policy**: UniformPolicy on concepts [C1, C2, C6]\n",
    "- **Strategy**: DoIntervention with constant value -10\n",
    "- This sets the selected concepts to a fixed value of -10 for a uniform subset of samples"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "int_policy_c = UniformPolicy(out_features=c_train.shape[1])\n",
    "int_strategy_c = DoIntervention(model=model[\"encoder_layer\"], constants=-10)\n",
    "\n",
    "print(\"Do Intervention + Uniform Policy:\")\n",
    "with intervention(\n",
    "    policies=int_policy_c,\n",
    "    strategies=int_strategy_c,\n",
    "    target_concepts=[1],\n",
    ") as new_encoder_layer:\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = new_encoder_layer(embedding=emb)\n",
    "    y_pred = model[\"y_predictor\"](endogenous=c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5, :2])"
   ],
   "id": "7975345e3d901890"
  },
  {
   "cell_type": "markdown",
   "id": "3cf55089",
   "metadata": {},
   "source": [
    "### 7.3. Do Intervention + Random Policy\n",
    "\n",
    "- **Policy**: RandomPolicy on concepts [C1, C2, C6] with scale=100\n",
    "- **Strategy**: DoIntervention with constant value -10\n",
    "- This randomly selects samples to intervene on, setting their selected concepts to -10"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "int_policy_c = RandomPolicy(out_features=c_train.shape[1])\n",
    "int_strategy_c = DoIntervention(model=encoder_layer, constants=-10)\n",
    "\n",
    "print(\"Do Intervention + Random Policy:\")\n",
    "with intervention(\n",
    "    policies=int_policy_c,\n",
    "    strategies=int_strategy_c,\n",
    "    target_concepts=[0, 1],\n",
    "    quantiles=0.5\n",
    ") as new_encoder_layer:\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = new_encoder_layer(embedding=emb)\n",
    "    y_pred = model[\"y_predictor\"](endogenous=c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5, :2])"
   ],
   "id": "dc8d32b749910de8"
  },
  {
   "cell_type": "markdown",
   "id": "b9ec6197",
   "metadata": {},
   "source": [
    "### 7.4. Distribution Intervention\n",
    "\n",
    "- **Policy**: RandomPolicy (reusing from previous cell)\n",
    "- **Strategy**: DistributionIntervention with Normal(0, 1)\n",
    "- This samples from a normal distribution for the intervened concepts instead of using a fixed constant"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9865e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T09:09:50.897132Z",
     "start_time": "2025-11-17T09:09:50.892771Z"
    }
   },
   "source": [
    "int_strategy_c = DistributionIntervention(model=encoder_layer, dist=torch.distributions.Normal(loc=50, scale=1))\n",
    "\n",
    "print(\"Distribution Intervention:\")\n",
    "with intervention(\n",
    "    policies=int_policy_c,\n",
    "    strategies=int_strategy_c,\n",
    "    target_concepts=[1, 3],\n",
    "    quantiles=.5\n",
    ") as new_encoder_layer:\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = new_encoder_layer(embedding=emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Intervention:\n",
      "\n",
      "Concept predictions (first 5):\n",
      "tensor([[ -4.8956,  20.1472,  -4.9395,  49.2009,  -1.9786,  21.0479],\n",
      "        [  9.6034,  50.4893,   8.3762,   4.9804,   7.0057,   4.9587],\n",
      "        [-13.6898, -16.0129, -15.2738,  49.5025, -12.4378, -17.0760],\n",
      "        [-18.1545,  14.0004, -18.9113,  47.5268,  -9.7617,  14.2617],\n",
      "        [  4.9382,  52.9688,   4.5033,  10.8236,   2.3549,  10.8078]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "472dea58",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded a toy XOR dataset with concept annotations\n",
    "2. Created semantic annotations for concepts and tasks\n",
    "3. Built a concept bottleneck model with encoder and predictor layers\n",
    "4. Trained the model with both concept and task supervision\n",
    "5. Demonstrated various intervention strategies:\n",
    "   - Ground truth interventions\n",
    "   - Do interventions (constant values)\n",
    "   - Distribution interventions (sampling from distributions)\n",
    "   - Different policies (Uniform, Random, Uncertainty-based)\n",
    "\n",
    "These interventions allow us to manipulate the model's concept representations and observe how they affect the final predictions, providing interpretability and control over the model's reasoning process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptarium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
