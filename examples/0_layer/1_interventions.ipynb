{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d49079",
   "metadata": {},
   "source": [
    "# Concept-Based Model with Interventions\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and prepare data with concept annotations\n",
    "2. Build a concept-based neural network with an encoder and predictor\n",
    "3. Train the model on both concept and task predictions\n",
    "4. Apply various intervention strategies to manipulate concept predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ced03c",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We import the necessary libraries:\n",
    "- **PyTorch**: for neural network building blocks\n",
    "- **sklearn**: for evaluation metrics\n",
    "- **torch_concepts**: for concept annotations, layers, and intervention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f0e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torch_concepts import Annotations, AxisAnnotation\n",
    "from torch_concepts.data import ToyDataset\n",
    "from torch_concepts.nn import (\n",
    "    ProbEncoderFromEmb, \n",
    "    ProbPredictor, \n",
    "    GroundTruthIntervention,\n",
    "    UncertaintyInterventionPolicy, \n",
    "    intervention, \n",
    "    DoIntervention, \n",
    "    DistributionIntervention, \n",
    "    UniformPolicy, \n",
    "    RandomPolicy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3341630",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "We load the XOR toy dataset and prepare the training data:\n",
    "- **Features (x_train)**: input features for the model\n",
    "- **Concepts (c_train)**: intermediate concept labels (duplicated to create 6 concepts)\n",
    "- **Targets (y_train)**: task labels to predict\n",
    "- **Names**: concept and task attribute names for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b49772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded:\n",
      "  Features shape: torch.Size([1000, 2])\n",
      "  Concepts shape: torch.Size([1000, 6])\n",
      "  Targets shape: torch.Size([1000, 1])\n",
      "  Number of features: 2\n",
      "  Number of concepts: 6\n",
      "  Number of classes: 1\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "latent_dims = 10\n",
    "n_epochs = 500\n",
    "n_samples = 1000\n",
    "concept_reg = 0.5\n",
    "\n",
    "# Load toy XOR dataset\n",
    "data = ToyDataset('xor', size=n_samples, random_state=42)\n",
    "x_train = data.data\n",
    "c_train = data.concept_labels\n",
    "y_train = data.target_labels\n",
    "concept_names = data.concept_attr_names\n",
    "task_names = data.task_attr_names\n",
    "\n",
    "# Duplicate concept labels to create 6 concepts (C1, C2, C3, C4, C5, C6)\n",
    "c_train = torch.concat([c_train, c_train, c_train], dim=1)\n",
    "\n",
    "# Get dimensions\n",
    "n_features = x_train.shape[1]\n",
    "n_concepts = c_train.shape[1]\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Features shape: {x_train.shape}\")\n",
    "print(f\"  Concepts shape: {c_train.shape}\")\n",
    "print(f\"  Targets shape: {y_train.shape}\")\n",
    "print(f\"  Number of features: {n_features}\")\n",
    "print(f\"  Number of concepts: {n_concepts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06618192",
   "metadata": {},
   "source": [
    "## 3. Annotations Object\n",
    "\n",
    "The `Annotations` object is a key component that provides semantic meaning to tensor dimensions:\n",
    "- It maps axis indices to `AxisAnnotation` objects\n",
    "- Each `AxisAnnotation` contains names (labels) for features along that axis\n",
    "- This enables human-readable concept manipulation and intervention\n",
    "\n",
    "Here we create:\n",
    "- **c_annotations**: annotations for the 6 concepts (C1-C6)\n",
    "- **y_annotations**: annotations for the task output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7a2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept annotations:\n",
      "  Shape: (-1, 6)\n",
      "  Axis 1 names: ['C1', 'C2', 'C3', 'C4', 'C5', 'C6']\n",
      "\n",
      "Task annotations:\n",
      "  Shape: (-1, 1)\n",
      "  Axis 1 names: ['xor']\n"
     ]
    }
   ],
   "source": [
    "# Create annotations for concepts and targets\n",
    "c_annotations = Annotations({1: AxisAnnotation(concept_names + ['C3', 'C4', 'C5', 'C6'])})\n",
    "y_annotations = Annotations({1: AxisAnnotation(task_names)})\n",
    "\n",
    "print(f\"Concept annotations:\")\n",
    "print(f\"  Shape: {c_annotations.shape}\")\n",
    "print(f\"  Axis 1 names: {c_annotations[1].labels}\")\n",
    "print(f\"\\nTask annotations:\")\n",
    "print(f\"  Shape: {y_annotations.shape}\")\n",
    "print(f\"  Axis 1 names: {y_annotations[1].labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e32f29",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "We build a concept bottleneck model with three components:\n",
    "\n",
    "1. **Encoder**: A simple neural network that maps input features to a latent embedding\n",
    "2. **Encoder Layer** (`ProbEncoderFromEmb`): Maps the embedding to concept logits\n",
    "3. **Task Predictor** (`ProbPredictor`): Maps concept logits to task predictions\n",
    "\n",
    "The model is wrapped in a `ModuleDict` to enable easier intervention on specific layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fab0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "ModuleDict(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (encoder_layer): ProbEncoderFromEmb(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=6, bias=True)\n",
      "      (1): Unflatten(dim=-1, unflattened_size=(6,))\n",
      "    )\n",
      "  )\n",
      "  (y_predictor): ProbPredictor(\n",
      "    (predictor): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=1, bias=True)\n",
      "      (1): Unflatten(dim=-1, unflattened_size=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Encoder layer representation:\n",
      "  Input: embedding of size 10\n",
      "  Output: concept logits of size 6\n",
      "\n",
      "Task predictor representation:\n",
      "  Input: concept logits of size 6\n",
      "  Output: task logits of size 1\n"
     ]
    }
   ],
   "source": [
    "# Build the encoder (features -> embedding)\n",
    "encoder = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_features, latent_dims),\n",
    "    torch.nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "# Build the concept encoder (embedding -> concepts)\n",
    "encoder_layer = ProbEncoderFromEmb(\n",
    "    in_features_embedding=latent_dims, \n",
    "    out_features=c_annotations.shape[1]\n",
    ")\n",
    "\n",
    "# Build the task predictor (concepts -> task)\n",
    "y_predictor = ProbPredictor(\n",
    "    in_features_logits=c_annotations.shape[1], \n",
    "    out_features=y_annotations.shape[1]\n",
    ")\n",
    "\n",
    "# Wrap all components in a ModuleDict for easier intervention\n",
    "model = torch.nn.ModuleDict({\n",
    "    \"encoder\": encoder,\n",
    "    \"encoder_layer\": encoder_layer,\n",
    "    \"y_predictor\": y_predictor,\n",
    "})\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nEncoder layer representation:\")\n",
    "print(f\"  Input: embedding of size {latent_dims}\")\n",
    "print(f\"  Output: concept logits of size {c_annotations.shape[1]}\")\n",
    "print(f\"\\nTask predictor representation:\")\n",
    "print(f\"  Input: concept logits of size {c_annotations.shape[1]}\")\n",
    "print(f\"  Output: task logits of size {y_annotations.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed2931",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "We train the model with a combined loss:\n",
    "- **Concept loss**: BCE loss between predicted and true concept labels\n",
    "- **Task loss**: BCE loss between predicted and true task labels\n",
    "- **Total loss**: `concept_loss + concept_reg * task_loss`\n",
    "\n",
    "This encourages the model to learn meaningful concept representations while also solving the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752e7ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 1.05 | Task Acc: 0.49 | Concept Acc: 0.00\n",
      "Epoch 100: Loss 0.53 | Task Acc: 0.57 | Concept Acc: 0.95\n",
      "Epoch 200: Loss 0.43 | Task Acc: 0.33 | Concept Acc: 0.98\n",
      "Epoch 300: Loss 0.41 | Task Acc: 0.32 | Concept Acc: 0.99\n",
      "Epoch 400: Loss 0.39 | Task Acc: 0.47 | Concept Acc: 0.99\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    emb = encoder(x_train)\n",
    "    c_pred = encoder_layer(embedding=emb)\n",
    "    y_pred = y_predictor(logits=c_pred)\n",
    "\n",
    "    # Compute loss\n",
    "    concept_loss = loss_fn(c_pred, c_train)\n",
    "    task_loss = loss_fn(y_pred, y_train)\n",
    "    loss = concept_loss + concept_reg * task_loss\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log progress\n",
    "    if epoch % 100 == 0:\n",
    "        task_accuracy = accuracy_score(y_train, y_pred > 0.)\n",
    "        concept_accuracy = accuracy_score(c_train, c_pred > 0.)\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item():.2f} | Task Acc: {task_accuracy:.2f} | Concept Acc: {concept_accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59499d42",
   "metadata": {},
   "source": [
    "## 6. Baseline Predictions (No Intervention)\n",
    "\n",
    "Let's first see what the model predicts without any interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892a2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline concept predictions (first 5 samples):\n",
      "tensor([[ -4.4402,  17.9389,  -4.3347,  17.1459,  -4.6396,  18.0594],\n",
      "        [  9.4854,   3.7959,   9.2281,   3.5878,   9.5774,   3.7644],\n",
      "        [-11.7614, -10.9780, -11.4861, -10.4635, -11.7920, -11.0394],\n",
      "        [-15.8845,  13.0674, -15.4057,  12.5706, -16.3195,  13.2554],\n",
      "        [  4.3424,   8.2338,   4.2186,   7.8436,   4.3349,   8.2514]])\n",
      "\n",
      "Baseline task predictions (first 5 samples):\n",
      "tensor([[ 0.1080],\n",
      "        [-0.0065],\n",
      "        [ 0.0425],\n",
      "        [ 0.1098],\n",
      "        [-0.0042]])\n"
     ]
    }
   ],
   "source": [
    "# Get baseline predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "\n",
    "print(\"Baseline concept predictions (first 5 samples):\")\n",
    "print(c_pred[:5])\n",
    "print(\"\\nBaseline task predictions (first 5 samples):\")\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa4cf3",
   "metadata": {},
   "source": [
    "## 7. Interventions\n",
    "\n",
    "Now we demonstrate different intervention strategies:\n",
    "\n",
    "### What are Interventions?\n",
    "Interventions allow us to manipulate the model's internal representations (concepts) during inference. This is useful for:\n",
    "- Understanding model behavior\n",
    "- Correcting mistakes\n",
    "- Testing counterfactual scenarios\n",
    "\n",
    "### Intervention Components:\n",
    "1. **Policy**: Decides *which* concepts to intervene on (e.g., UniformPolicy, RandomPolicy, UncertaintyInterventionPolicy)\n",
    "2. **Strategy**: Decides *how* to intervene (e.g., DoIntervention, GroundTruthIntervention, DistributionIntervention)\n",
    "3. **Layer**: Specifies *where* in the model to apply the intervention\n",
    "4. **Quantile**: Controls *how many* samples to intervene on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dfb55",
   "metadata": {},
   "source": [
    "### 7.1. Uncertainty + Ground Truth Intervention\n",
    "\n",
    "- **Policy**: UniformPolicy on concepts [C1, C4, C5, C6] + UncertaintyInterventionPolicy on task [xor]\n",
    "- **Strategy**: GroundTruthIntervention (use true concept values) + DoIntervention (set to constant 100)\n",
    "- This combination intervenes on uncertain predictions using ground truth for concepts and a constant for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6b27ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty + Ground Truth Intervention:\n",
      "\n",
      "Concept predictions (first 5):\n",
      "tensor([[-13.8155,  17.9389,  -4.3347,  13.8023, -13.8155,  13.8023],\n",
      "        [ 13.8023,   3.7959,   9.2281,  13.8023,  13.8023,  13.8023],\n",
      "        [-13.8155, -10.9780, -11.4861, -13.8155, -13.8155, -13.8155],\n",
      "        [-13.8155,  13.0674, -15.4057,  13.8023, -13.8155,  13.8023],\n",
      "        [ 13.8023,   8.2338,   4.2186,  13.8023,  13.8023,  13.8023]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Task predictions (first 5):\n",
      "tensor([[100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "quantile = 0.8\n",
    "\n",
    "int_policy_c = UniformPolicy(out_annotations=c_annotations, subset=[\"C1\", \"C4\", \"C5\", \"C6\"])\n",
    "int_strategy_c = GroundTruthIntervention(model=model, ground_truth=torch.logit(c_train, eps=1e-6))\n",
    "int_policy_y = UncertaintyInterventionPolicy(out_annotations=y_annotations, subset=[\"xor\"])\n",
    "int_strategy_y = DoIntervention(model=model, constants=100)\n",
    "\n",
    "print(\"Uncertainty + Ground Truth Intervention:\")\n",
    "with intervention(\n",
    "    policies=[int_policy_c, int_policy_y],\n",
    "    strategies=[int_strategy_c, int_strategy_y],\n",
    "    on_layers=[\"encoder_layer.encoder\", \"y_predictor.predictor\"],\n",
    "    quantiles=[quantile, 1]\n",
    "):\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])\n",
    "    print(\"\\nTask predictions (first 5):\")\n",
    "    print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189cec30",
   "metadata": {},
   "source": [
    "### 7.2. Do Intervention + Uniform Policy\n",
    "\n",
    "- **Policy**: UniformPolicy on concepts [C1, C2, C6]\n",
    "- **Strategy**: DoIntervention with constant value -10\n",
    "- This sets the selected concepts to a fixed value of -10 for a uniform subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f132cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do Intervention + Uniform Policy:\n",
      "\n",
      "Concept predictions (first 5):\n",
      "tensor([[-10.0000, -10.0000,  -4.3347,  17.1459,  -4.6396, -10.0000],\n",
      "        [-10.0000, -10.0000,   9.2281,   3.5878,   9.5774, -10.0000],\n",
      "        [-10.0000, -10.0000, -11.4861, -10.4635, -11.7920, -10.0000],\n",
      "        [-10.0000, -10.0000, -15.4057,  12.5706, -16.3195, -10.0000],\n",
      "        [-10.0000, -10.0000,   4.2186,   7.8436,   4.3349, -10.0000]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "int_policy_c = UniformPolicy(out_annotations=c_annotations, subset=[\"C1\", \"C2\", \"C6\"])\n",
    "int_strategy_c = DoIntervention(model=model, constants=-10)\n",
    "\n",
    "print(\"Do Intervention + Uniform Policy:\")\n",
    "with intervention(\n",
    "    policies=[int_policy_c],\n",
    "    strategies=[int_strategy_c],\n",
    "    on_layers=[\"encoder_layer.encoder\"],\n",
    "    quantiles=[quantile]\n",
    "):\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf55089",
   "metadata": {},
   "source": [
    "### 7.3. Do Intervention + Random Policy\n",
    "\n",
    "- **Policy**: RandomPolicy on concepts [C1, C2, C6] with scale=100\n",
    "- **Strategy**: DoIntervention with constant value -10\n",
    "- This randomly selects samples to intervene on, setting their selected concepts to -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_policy_c = RandomPolicy(out_annotations=c_annotations, scale=100, subset=[\"C1\", \"C2\", \"C6\"])\n",
    "int_strategy_c = DoIntervention(model=model, constants=-10)\n",
    "\n",
    "print(\"Do Intervention + Random Policy:\")\n",
    "with intervention(\n",
    "    policies=[int_policy_c],\n",
    "    strategies=[int_strategy_c],\n",
    "    on_layers=[\"encoder_layer.encoder\"],\n",
    "    quantiles=[quantile]\n",
    "):\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec6197",
   "metadata": {},
   "source": [
    "### 7.4. Distribution Intervention\n",
    "\n",
    "- **Policy**: RandomPolicy (reusing from previous cell)\n",
    "- **Strategy**: DistributionIntervention with Normal(0, 1)\n",
    "- This samples from a normal distribution for the intervened concepts instead of using a fixed constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9865e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Intervention:\n",
      "\n",
      "Concept predictions (first 5):\n",
      "tensor([[ -1.3485,   0.7330,  -4.3347,  17.1459,  -4.6396,   0.1784],\n",
      "        [ -0.1086,   0.8196,   9.2281,   3.5878,   9.5774,  -1.8287],\n",
      "        [ -0.8125,  -0.5722, -11.4861, -10.4635, -11.7920,  -0.9029],\n",
      "        [  0.9016,   1.7261, -15.4057,  12.5706, -16.3195,  -0.9566],\n",
      "        [  2.4360,  -1.2420,   4.2186,   7.8436,   4.3349,   2.6420]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "int_strategy_c = DistributionIntervention(\n",
    "    model=model, \n",
    "    dist=torch.distributions.Normal(loc=0, scale=1)\n",
    ")\n",
    "\n",
    "print(\"Distribution Intervention:\")\n",
    "with intervention(\n",
    "    policies=[int_policy_c],\n",
    "    strategies=[int_strategy_c],\n",
    "    on_layers=[\"encoder_layer.encoder\"],\n",
    "    quantiles=[quantile]\n",
    "):\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bd068",
   "metadata": {},
   "source": [
    "### 7.5. Single Intervention Example\n",
    "\n",
    "Demonstrating a simple single intervention with full output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dfc344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Intervention (Distribution):\n",
      "\n",
      "Concept predictions (first 5):\n",
      "tensor([[ -1.2687,   0.9846,  -4.3347,  17.1459,  -4.6396,   1.3569],\n",
      "        [  0.9104,  -0.4779,   9.2281,   3.5878,   9.5774,   0.1320],\n",
      "        [  0.3222,  -0.4628, -11.4861, -10.4635, -11.7920,   0.9773],\n",
      "        [ -1.2280,   0.2996, -15.4057,  12.5706, -16.3195,  -0.0471],\n",
      "        [ -0.5348,  -0.2769,   4.2186,   7.8436,   4.3349,   0.9744]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Task predictions (first 5):\n",
      "tensor([[ 0.0100],\n",
      "        [-0.1131],\n",
      "        [ 0.0264],\n",
      "        [-0.0171],\n",
      "        [-0.0655]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Single Intervention (Distribution):\")\n",
    "with intervention(\n",
    "    policies=[int_policy_c],\n",
    "    strategies=[int_strategy_c],\n",
    "    on_layers=[\"encoder_layer.encoder\"],\n",
    "    quantiles=[quantile]\n",
    "):\n",
    "    emb = model[\"encoder\"](x_train)\n",
    "    c_pred = model[\"encoder_layer\"](emb)\n",
    "    y_pred = model[\"y_predictor\"](c_pred)\n",
    "    print(\"\\nConcept predictions (first 5):\")\n",
    "    print(c_pred[:5])\n",
    "    print(\"\\nTask predictions (first 5):\")\n",
    "    print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dea58",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded a toy XOR dataset with concept annotations\n",
    "2. Created semantic annotations for concepts and tasks\n",
    "3. Built a concept bottleneck model with encoder and predictor layers\n",
    "4. Trained the model with both concept and task supervision\n",
    "5. Demonstrated various intervention strategies:\n",
    "   - Ground truth interventions\n",
    "   - Do interventions (constant values)\n",
    "   - Distribution interventions (sampling from distributions)\n",
    "   - Different policies (Uniform, Random, Uncertainty-based)\n",
    "\n",
    "These interventions allow us to manipulate the model's concept representations and observe how they affect the final predictions, providing interpretability and control over the model's reasoning process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptarium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
